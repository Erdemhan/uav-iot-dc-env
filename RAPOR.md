# PROJE GELÄ°ÅÄ°M RAPORU VE TEKNÄ°K DOKÃœMANTASYON

**Proje BaÅŸlÄ±ÄŸÄ±:** Nesnelerin Ä°nterneti TabanlÄ± Ä°HA UygulamalarÄ±nda GÃ¼venlik Hassasiyetli AkÄ±llÄ± YÃ¶ntemlerin GeliÅŸtirilmesi
**Rapor Tarihi:** 02.02.2026 01:07
**Versiyon:** 2.2.0 (Robustness SÃ¼rÃ¼mÃ¼)

---

## 1. GÄ°RÄ°Å VE SÄ°STEM GENEL BAKIÅI

Bu proje, Doktora Tezi kapsamÄ±nda Ä°nsansÄ±z Hava AraÃ§larÄ± (Ä°HA) ve Nesnelerin Ä°nterneti (IoT) aÄŸlarÄ±nÄ±n entegre Ã§alÄ±ÅŸtÄ±ÄŸÄ± senaryolarda, siber gÃ¼venlik tehditlerinin (Ã¶zellikle Jamming saldÄ±rÄ±larÄ±) etkilerini analiz etmek ve bunlara karÅŸÄ± dayanÄ±klÄ± akÄ±llÄ± yÃ¶ntemler geliÅŸtirmek amacÄ±yla tasarlanmÄ±ÅŸtÄ±r.

GeliÅŸtirilen simÃ¼lasyon ortamÄ±, literatÃ¼rdeki standartlara uygun olarak Python tabanlÄ±, modÃ¼ler, geniÅŸletilebilir ve bilimsel geÃ§erliliÄŸi olan matematiksel modellere dayalÄ± bir altyapÄ±ya sahiptir. OpenAI Gymnasium arayÃ¼zÃ¼ benimsenerek, Baseline (QJC), DRL (PPO, DQN) ve Bellek TabanlÄ± (PPO-LSTM) algoritmalarÄ±n entegre Ã§alÄ±ÅŸabildiÄŸi kapsamlÄ± bir test yataÄŸÄ± (testbed) oluÅŸturulmuÅŸtur.

---

## 2. Ä°LGÄ°LÄ° Ã‡ALIÅMALAR (LÄ°TERATÃœR Ã–ZETÄ°)

Ä°HA destekli iletiÅŸim aÄŸlarÄ±nda karÄ±ÅŸtÄ±rma (jamming) saldÄ±rÄ±larÄ±na karÅŸÄ± gÃ¼venilirlik saÄŸlama problemi Ã¼Ã§ ana eksende incelenmiÅŸtir:

### 2.1. Oyun Teorisi TabanlÄ± YaklaÅŸÄ±mlar
Liao et al. (2025), Ä°HA konuÅŸlandÄ±rmasÄ±nÄ± bir **TÄ±kanÄ±klÄ±k Oyunu (Congestion Game)** ve taÅŸÄ±yÄ±cÄ± seÃ§imini **Stackelberg Oyunu** olarak modellemiÅŸtir. Bu yÃ¶ntemler matematiksel bir denge (Nash Equilibrium) garantisi sunsa da, oyuncularÄ±n tam rasyonel olduÄŸunu varsayar ve dinamik tehditlere adaptasyon sÃ¼releri uzundur.

### 2.2. Geleneksel YÃ¶ntemler
ParÃ§acÄ±k SÃ¼rÃ¼ Optimizasyonu (PSO) ve BulanÄ±k C-Means (FCM) gibi sezgisel algoritmalar genellikle statik ortam optimizasyonu iÃ§in kullanÄ±lÄ±r. DÃ¼ÅŸman (adversarial) bir jammerÄ±n anlÄ±k strateji deÄŸiÅŸtirdiÄŸi senaryolarda yetersiz kalabilirler.

### 2.3. PekiÅŸtirmeli Ã–ÄŸrenme (RL) YaklaÅŸÄ±mlarÄ±
QJC (Q-Learning Based Jamming) gibi temel RL yÃ¶ntemleri, dÃ¼ÅŸÃ¼k iÅŸlem maliyeti sunar ancak genellikle "kÃ¶r" (blind) stratejilerdir; yani ortamÄ± algÄ±lamadan sadece Ã¶dÃ¼l geÃ§miÅŸine bakarlar.

**Ã–nerilen YÃ¶ntem:** Ã‡alÄ±ÅŸmamÄ±zda kullanÄ±lan PPO ve DQN algoritmalarÄ±, jammerÄ±n sinyal gÃ¼cÃ¼nÃ¼ (RSS) ve spektrum doluluÄŸunu algÄ±ladÄ±ÄŸÄ± "Smart Jammer" modeline dayanÄ±r. Bu, kÃ¶r Ã¶ÄŸrenme yerine **durum-farkÄ±nda (state-aware)** ve veriye dayalÄ± (data-driven) bir savunma/saldÄ±rÄ± mekanizmasÄ± saÄŸlar.

## 3. SÄ°STEM MÄ°MARÄ°SÄ°

SimÃ¼lasyon altyapÄ±sÄ±, Nesne YÃ¶nelimli Programlama (OOP) prensipleri Ã§erÃ§evesinde, her biri spesifik bir gÃ¶revi Ã¼stlenen gevÅŸek baÄŸlÄ± (loose-coupled) modÃ¼llerden oluÅŸmaktadÄ±r.

### 3.1. KonfigÃ¼rasyon ModÃ¼lleri (`confs/`)

*   **`confs/config.py` (Sistem KonfigÃ¼rasyonu):** Sistemin fiziksel bant geniÅŸliÄŸi, frekans, gÃ¼rÃ¼ltÃ¼ seviyesi gibi temel donanÄ±m parametrelerini tutar.
*   **`confs/env_config.py` (Ortam ve Senaryo KonfigÃ¼rasyonu):** SimÃ¼lasyonun senaryo parametrelerini (DÃ¼ÄŸÃ¼m sayÄ±sÄ±, alan boyutu, adÄ±m sÃ¼resi, saldÄ±rgan konumu vb.) barÄ±ndÄ±rÄ±r. Bu ayrÄ±m sayesinde fiziksel altyapÄ± deÄŸiÅŸtirilmeden farklÄ± senaryolar test edilebilir.

### 3.2. Ã‡ekirdek ModÃ¼ller (`core/`)
*   **`core/physics.py` (Fizik Motoru):** Sistemin "stateless" (durumsuz) matematiksel hesaplama Ã§ekirdeÄŸidir. HaberleÅŸme kanalÄ± (Path Loss, SINR, Shannon Kapasitesi) ve enerji tÃ¼ketim modelleri (Ä°HA uÃ§uÅŸ gÃ¼cÃ¼, IoT iletim enerjisi) burada saf fonksiyonlar (pure functions) olarak implemente edilmiÅŸtir.
*   **`simulation/entities.py` (VarlÄ±k Modellemesi):** SimÃ¼lasyon dÃ¼nyasÄ±ndaki aktÃ¶rlerin (Ä°HA, IoT DÃ¼ÄŸÃ¼mÃ¼, SaldÄ±rgan) davranÄ±ÅŸlarÄ±nÄ± ve durumlarÄ±nÄ± modelleyen sÄ±nÄ±flarÄ± iÃ§erir.
    *   *Miras YapÄ±sÄ±:* `BaseEntity` -> `MobileEntity` / `TransceiverEntity` -> `UAVAgent` / `IoTNode` ÅŸeklinde hiyerarÅŸik bir yapÄ± kurgulanmÄ±ÅŸtÄ±r.

### 3.3. SimÃ¼lasyon ve Ortam
*   **`simulation/pettingzoo_env.py` (PettingZoo OrtamÄ±):** `UAV_IoT_PZ_Env` sÄ±nÄ±fÄ±, simÃ¼lasyonun Ã§oklu ajan (multi-agent) yapÄ±sÄ±nÄ± destekleyen `pettingzoo.utils.ParallelEnv` tabanlÄ± ortamdÄ±r. Ä°HA, SaldÄ±rgan ve her bir IoT dÃ¼ÄŸÃ¼mÃ¼ ayrÄ± birer ajan olarak modellenmiÅŸtir.
*   **`simulation/controllers.py` (Kural TabanlÄ± KontrolcÃ¼ler):** Ä°HA gibi belirli kurallara (Ã¶rn. navigasyon) dayalÄ± hareket eden ajanlarÄ±n davranÄ±ÅŸ mantÄ±ÄŸÄ±nÄ± kapsÃ¼ller.
*   **`scripts/main.py` (YÃ¼rÃ¼tÃ¼cÃ¼):** SimÃ¼lasyon dÃ¶ngÃ¼sÃ¼nÃ¼ PettingZoo API'sine uygun ÅŸekilde (sÃ¶zlÃ¼k yapÄ±lÄ± aksiyon/gÃ¶zlem) yÃ¶netir. `confs/config.py` iÃ§erisindeki `SIMULATION_DELAY` parametresi ile simÃ¼lasyon akÄ±ÅŸ hÄ±zÄ± kontrol edilebilir.

### 3.4. Veri YÃ¶netimi ve Analiz

*   **`core/logger.py` (Telemetri KaydÄ±):** SimÃ¼lasyon sÄ±rasÄ±nda Ã¼retilen ham verileri (konumlar, SINR deÄŸerleri, enerji tÃ¼ketimleri) periyodik olarak CSV formatÄ±nda kayÄ±t altÄ±na alÄ±r.

*   **`visualization/visualizer.py` (GÃ¶rsel Analiz):** SimÃ¼lasyon sonrasÄ± elde edilen verileri iÅŸleyerek akademik kalitede (SCIE standartlarÄ±nda) grafikler ve yÃ¶rÃ¼nge analizleri Ã¼retir.

### 3.5. KullanÄ±lan AltyapÄ± ve Teknolojiler

Projenin geliÅŸtirilmesinde, akademik standartlara uygunluk ve yÃ¼ksek performans gereksinimleri gÃ¶zetilerek aÅŸaÄŸÄ±daki aÃ§Ä±k kaynaklÄ± kÃ¼tÃ¼phaneler kullanÄ±lmÄ±ÅŸtÄ±r:

*   **PettingZoo (Python):** Ã‡oklu ajan (Multi-Agent) takviyeli Ã¶ÄŸrenme ortamlarÄ± iÃ§in endÃ¼stri standardÄ± olan bu kÃ¼tÃ¼phane, projemizin temel yapÄ± taÅŸÄ±dÄ±r. `ParallelEnv` API'si kullanÄ±larak, Ä°HA, Jammer ve IoT dÃ¼ÄŸÃ¼mlerinin eÅŸ zamanlÄ± olarak etkileÅŸime girdiÄŸi, Ã¶lÃ§eklenebilir ve oyun teorik analizlere uygun bir simÃ¼lasyon ortamÄ± oluÅŸturulmuÅŸtur.
*   **OpenAI Gymnasium:** PettingZoo'nun Ã¼zerine inÅŸa edildiÄŸi temel API yapÄ±sÄ±dÄ±r. AjanlarÄ±n durum-aksiyon uzaylarÄ±nÄ±n (Box, Discrete) tanÄ±mlanmasÄ±nda standartlarÄ± belirler.
*   **NumPy:** YÃ¼ksek performanslÄ± vektÃ¶rel matematik iÅŸlemleri iÃ§in kullanÄ±lmÄ±ÅŸtÄ±r. Fizik motorundaki (`physics.py`) sinyal gÃ¼cÃ¼, SINR ve enerji hesaplamalarÄ±, dÃ¶ngÃ¼ler yerine NumPy vektÃ¶r operasyonlarÄ± ile optimize edilerek simÃ¼lasyon hÄ±zÄ± artÄ±rÄ±lmÄ±ÅŸtÄ±r.
*   **Matplotlib:** SimÃ¼lasyon verilerinin gÃ¶rselleÅŸtirilmesi ve analiz grafiklerinin (`trajectory.png`, `metrics_analysis.png`) oluÅŸturulmasÄ± iÃ§in kullanÄ±lmÄ±ÅŸtÄ±r.
*   **Pandas:** SimÃ¼lasyon loglarÄ±nÄ±n (`history.csv`) iÅŸlenmesi, filtrelenmesi ve zaman serisi analizlerinin yapÄ±lmasÄ± amacÄ±yla veri manipÃ¼lasyonu iÃ§in tercih edilmiÅŸtir.
*   **Ray RLLib:** DaÄŸÄ±tÄ±k (Distributed) Reinforcement Learning eÄŸitimi iÃ§in kullanÄ±lmÄ±ÅŸtÄ±r. PPO (Proximal Policy Optimization) gibi geliÅŸmiÅŸ algoritmalarÄ±n, Ã§oklu ajan (PettingZoo) ortamÄ±mÄ±zla entegre bir ÅŸekilde Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ±nÄ± ve modelin (`train.py` Ã¼zerinden) eÄŸitilmesini saÄŸlayan temel kÃ¼tÃ¼phanedir.

### 3.6. Mevcut SimÃ¼lasyon Senaryosu (v1.7.0 - AkÄ±llÄ± Tehdit Modeli)

Bu sÃ¼rÃ¼mde (v2.2.0) kullanÄ±lan senaryo, "Adil, KÄ±yaslanabilir ve Robust AkÄ±llÄ± Tehdit" modelidir.

*   **Operasyonel Alan:** 1000m x 1000m boyutlarÄ±nda 2 boyutlu dÃ¼zlem.
*   **Frekans Spektrumu:** Sistem 3 farklÄ± frekans kanalÄ±nda (2.4, 5.0, 5.8 GHz) Ã§alÄ±ÅŸabilmektedir.
*   **Ä°HA DavranÄ±ÅŸÄ± (Blue Team - Reaktif Hedef):**
    *   **GÃ¶rev:** 5 adet IoT dÃ¼ÄŸÃ¼mÃ¼nÃ¼ sÄ±rayla ziyaret edip veri toplamak.
    *   **Tepkisellik:** EÄŸer Ä°HA saldÄ±rÄ±ya uÄŸrarsa (SINR < 0dB), bulunduÄŸu kanalÄ± terk eder ve bir sonraki adÄ±ma **Markov GeÃ§iÅŸ Matrisi** (Transition Matrix) ile karar verir. Yani kaÃ§Ä±ÅŸÄ± rastgele deÄŸil, belirli bir istatistiksel Ã¶rÃ¼ntÃ¼ye dayalÄ±dÄ±r.
*   **SaldÄ±rgan DavranÄ±ÅŸÄ± (Red Team - AkÄ±llÄ± Ajan):**
    *   **AmaÃ§:** Ä°HA'nÄ±n kanal deÄŸiÅŸtirme Ã¶rÃ¼ntÃ¼sÃ¼nÃ¼ Ã¶ÄŸrenip onu bloke etmek.
    *   **YÃ¶ntemler:** Baseline (Q-Learning), PPO (Deep RL) veya DQN (Deep Q-Network) algoritmalarÄ±yla eÄŸitilir.
    *   **KÄ±sÄ±tlar:** SÃ¼rekli yÃ¼ksek gÃ¼Ã§ basamaz (Enerji maliyeti) ve her frekansta aynÄ± verimlilikte deÄŸildir (PA Efficiency).
*   **AÄŸ Dinamikleri:**
    *   BaÅŸarÄ±lÄ± iletiÅŸim iÃ§in sadece mesafe yetmez, **Kanal Uyumu** (SaldÄ±rganla Ã§akÄ±ÅŸmama) gereklidir.

---

## 4. MATERYAL VE YÃ–NTEMLER

Bu bÃ¶lÃ¼m, sistemin fiziksel ve matematiksel altyapÄ±sÄ±nÄ± detaylandÄ±rmaktadÄ±r.

### 4.1. Sistem Modeli
Senaryo, $1000 \times 1000$ metrelik bir alana, $N=5$ adet IoT dÃ¼ÄŸÃ¼mÃ¼, 1 adet Ä°HA ve 1 adet AkÄ±llÄ± Jammer iÃ§ermektedir.

#### 4.1.1. HaberleÅŸme KanalÄ± (Air-to-Ground)
Ä°HA ile dÃ¼ÄŸÃ¼mler arasÄ±ndaki iletiÅŸim kalitesi, anlÄ±k **SINR (Signal-to-Interference-plus-Noise Ratio)** deÄŸeri ile belirlenir:

$$ \text{SINR}_i = \frac{P_{rx,i}}{N_0 B + I_{jam}} $$

Burada:
*   $P_{rx,i}$: Friis denklemi ile hesaplanan alÄ±nan sinyal gÃ¼cÃ¼ ($P_{tx} G ( \frac{\lambda}{4 \pi d} )^\alpha$).
*   $N_0 B$: Termal gÃ¼rÃ¼ltÃ¼ gÃ¼cÃ¼.
*   $I_{jam}$: Jammer'dan kaynaklanan giriÅŸim ($P_{jam} \times h_{jam}$).

**PA VerimliliÄŸi (GÃ¼Ã§ AmplifikatÃ¶rÃ¼):**
Sistem modelimiz, Cui et al. (2005) tarafÄ±ndan Ã¶nerilen frekansa baÄŸlÄ± verimlilik modelini kullanÄ±r. YÃ¼ksek frekanslarda gÃ¼Ã§ amplifikatÃ¶rÃ¼ (PA) verimliliÄŸi dÃ¼ÅŸer:
*   **2.4 GHz:** $\eta \approx 0.50$ (Daha verimli)
*   **5.0 GHz:** $\eta \approx 0.25$
*   **5.8 GHz:** $\eta \approx 0.19$ (Daha maliyetli)
Bu fiziksel kÄ±sÄ±t, Jammer'Ä±n "sadece yÃ¼ksek frekansta Ã§alÄ±ÅŸmak yerine enerji-verimli bandÄ± seÃ§me" stratejisini Ã¶ÄŸrenmesini zorunlu kÄ±lar.

#### 4.1.2. Enerji TÃ¼ketim Modelleri
*   **Ä°HA UÃ§uÅŸ Enerjisi:** Aerodinamik prensiplere dayalÄ± gÃ¼Ã§ tÃ¼ketimi $P_{UAV}(v)$:
    $$ P_{UAV}(v) = P_0 \left( 1 + \frac{3v^2}{U_{tip}^2} \right) + P_i \left( \sqrt{1 + \frac{v^4}{4v_0^4}} - \frac{v^2}{2v_0^2} \right)^{1/2} + \frac{1}{2} d_0 \rho s A v^3 $$
*   **IoT Enerjisi:** Veri toplama, ÅŸifreleme ve iletim ($E_{tx} = P_{tx} \times L/R$) maliyetlerinin toplamÄ±dÄ±r.
*   **Jammer Enerjisi:** SeÃ§ilen gÃ¼Ã§ seviyesinin PA verimliliÄŸine bÃ¶lÃ¼nmesiyle elde edilen toplam sistem gÃ¼cÃ¼dÃ¼r:
    $$ P_{sys} = \frac{P_{jam}}{\eta_{PA}(f)} + P_{circuit} $$
    Burada $\eta_{PA}(f)$, frekansa baÄŸlÄ± verimlilik (%50 @ 2.4GHz, %19 @ 5.8GHz) faktÃ¶rÃ¼dÃ¼r. Bu model, "Energy Efficiency" analizlerinin temelini oluÅŸturur.

### 4.2. Problem FormÃ¼lasyonu (MDP)
Problem, $\langle \mathcal{S}, \mathcal{A}, \mathcal{P}, \mathcal{R}, \gamma \rangle$ ile tanÄ±mlanan bir Markov Karar SÃ¼recidir.

*   **Durum UzayÄ± ($\mathcal{S}$):** UzaklÄ±k (RSS Proxy), Kanal Durumu, DÃ¼ÄŸÃ¼m BaÄŸlantÄ± HaritasÄ±.
*   **Aksiyon UzayÄ± ($\mathcal{A}$):** Kanal SeÃ§imi ($C_k$) ve GÃ¼Ã§ Seviyesi ($P_m$).
*   **Ã–dÃ¼l Fonksiyonu ($\mathcal{R}$):**
    $$ r_t = (w_{jam} \cdot N_{jammed}) + (w_{track} \cdot \mathbb{I}_{track}) - (w_{cost} \cdot E_{consumed}) $$

---

## 5. Ã–DÃœL (REWARD) MEKANÄ°ZMALARININ DETAYLI AÃ‡IKLAMASI

Jammer'Ä±n eÄŸitimi, Ã¼Ã§ farklÄ± algoritma iÃ§in (Baseline, PPO, DQN) dikkatli tasarlanmÄ±ÅŸ Ã¶dÃ¼l fonksiyonlarÄ± ile yÃ¶nlendirilmektedir. Bu Ã¶dÃ¼l yapÄ±larÄ±, hem jamming etkinliÄŸini maksimize ederken, hem de enerji verimliliÄŸini koruyan stratejilerin Ã¶ÄŸrenilmesini teÅŸvik eder.

### 5.1. Baseline (QJC AlgoritmasÄ±) Ã–dÃ¼l YapÄ±sÄ±

Klasik Q-Learning yaklaÅŸÄ±mÄ±, ayrÄ±k bir durum-aksiyon Ã¶dÃ¼l tablosu kullanÄ±r:

*   **Durum (State):** Mevcut kanal (0, 1, 2)
*   **Aksiyon (Action):** GÃ¼Ã§ seviyesi (0-9)
*   **Ã–dÃ¼l FormÃ¼lÃ¼:**
    ```
    Ã–dÃ¼l = (JamlenmiÅŸ_DÃ¼ÄŸÃ¼m_SayÄ±sÄ± Ã— 10) - (Enerji_TÃ¼ketimi Ã— 0.1)
    ```

Bu basit linear yapÄ±, tablosal Q-Learning iÃ§in yeterli geri bildirim saÄŸlar.

### 5.2. PPO & DQN (Derin Takviyeli Ã–ÄŸrenme) Ã–dÃ¼l YapÄ±sÄ±

Her iki derin Ã¶ÄŸrenme algoritmasÄ± da **aynÄ± Ã¼Ã§ bileÅŸenli** Ã¶dÃ¼l yapÄ±sÄ±nÄ± paylaÅŸÄ±r:

#### BileÅŸen 1: Jamming BaÅŸarÄ± Ã–dÃ¼lÃ¼ (Sparse, YÃ¼ksek DeÄŸer)
```
Ã¶dÃ¼l_baÅŸarÄ± = jamlenen_dÃ¼ÄŸÃ¼m_sayÄ±sÄ± Ã— 10
```
*   **AmaÃ§:** Birincil hedef - jamming etkinliÄŸini maksimize etmek
*   **AralÄ±k:** 0 ile 50 arasÄ± (5 dÃ¼ÄŸÃ¼m iÃ§in)
*   **Tip:** Seyrek Ã¶dÃ¼l (sadece jamming baÅŸarÄ±lÄ± olduÄŸunda verilir)

#### BileÅŸen 2: Kanal Takip Ã–dÃ¼lÃ¼ (Dense, DÃ¼ÅŸÃ¼k DeÄŸer)
```python
if (jammer_kanalÄ± == uav_kanalÄ± AND jammer_gÃ¼cÃ¼ > 0.01):
    Ã¶dÃ¼l_takip = 0.5
else:
    Ã¶dÃ¼l_takip = 0.0
```
*   **AmaÃ§:** Jammer'Ä± Ä°HA'nÄ±n frekans atlama davranÄ±ÅŸÄ±nÄ± takip etmesi iÃ§in yÃ¶nlendirmek
*   **KRÄ°TÄ°K KOÅUL:** Sadece **gÃ¼Ã§ kullanÄ±ldÄ±ÄŸÄ±nda** verilir (sÃ¶mÃ¼rÃ¼yÃ¼ Ã¶nler)
*   **Tip:** YoÄŸun rehberlik sinyali (her adÄ±mda kontrol edilir)
*   **TasarÄ±m MantÄ±ÄŸÄ±:** GÃ¼Ã§ eÅŸik kontrolÃ¼ (`> 0.01W`), ajanlarÄ±n "sÄ±fÄ±r gÃ¼Ã§le sadece kanal takibi yaparak Ã¶dÃ¼l alma" aÃ§Ä±ÄŸÄ±nÄ± kapatÄ±r.

#### BileÅŸen 3: Enerji Maliyet CezasÄ±
```
Ã¶dÃ¼l_enerji = -(jammer_gÃ¼Ã§_tÃ¼ketimi Ã— 0.1)
```
*   **AmaÃ§:** Enerji verimli jamming stratejilerini teÅŸvik etmek
*   **AralÄ±k:** 0 ile -0.01W (tipik deÄŸerler)
*   **Etki:** Gereksiz yÃ¼ksek gÃ¼Ã§ kullanÄ±mÄ±nÄ± cesaretlendirmez

#### Toplam Ã–dÃ¼l
```
toplam_Ã¶dÃ¼l = Ã¶dÃ¼l_baÅŸarÄ± + Ã¶dÃ¼l_takip - Ã¶dÃ¼l_enerji
```

### 5.3. Ã–dÃ¼l TasarÄ±mÄ±nÄ±n Teorik Temelleri

1.  **GÃ¼Ã§ EÅŸik KontrolÃ¼:**
    *   **Problem:** Ä°lk versiyonda takip Ã¶dÃ¼lÃ¼ (`+0.5`) gÃ¼Ã§ten baÄŸÄ±msÄ±zdÄ±.
    *   **SonuÃ§:** Ajanlar "Ä°HA kanalÄ±nÄ± takip et ama jamming yapma" ÅŸeklinde dejenere bir politika Ã¶ÄŸrendi.
    *   **Ã‡Ã¶zÃ¼m:** `power > 0.01W` koÅŸulu eklenerek, Ã¶dÃ¼lÃ¼n sadece gerÃ§ek jamming faaliyeti sÄ±rasÄ±nda verilmesi saÄŸlandÄ±.

2.  **Ã–lÃ§eklendirme Dengesi:**
    *   BaÅŸarÄ± Ã¶dÃ¼lÃ¼ (10Ã—) > Takip Ã¶dÃ¼lÃ¼ (0.5) â†’ Jamming birincil hedef olarak kalÄ±r.
    *   Enerji cezasÄ± (0.1Ã—) â†’ Jamming'i caydÄ±rmayacak kadar kÃ¼Ã§Ã¼k, ama verimsiz gÃ¼Ã§ kullanÄ±mÄ±nÄ± optimize edecek kadar anlamlÄ±.

3.  **Seyrek vs YoÄŸun Ã–dÃ¼l Trade-off'u:**
    *   **Seyrek (Jamming):** DoÄŸrudan hedefi yansÄ±tÄ±r ama Ã¶ÄŸrenmeyi zorlaÅŸtÄ±rÄ±r (credit assignment problem).
    *   **YoÄŸun (Takip):** Gradient akÄ±ÅŸÄ±nÄ± stabilize eder ve erken aÅŸamada keÅŸfi hÄ±zlandÄ±rÄ±r.
    *   **Birlikte:** Ä°ki Ã¶dÃ¼l tipi sinerjik Ã§alÄ±ÅŸarak hem exploration hem de exploitation'Ä± dengeÅŸtirir.

### 5.4. Algoritma KarÅŸÄ±laÅŸtÄ±rmasÄ± - Ã–dÃ¼l KullanÄ±mÄ±

| Metrik                  | Baseline (QJC) | PPO           | DQN           |
|-------------------------|----------------|---------------|---------------|
| **Ã–dÃ¼l YapÄ±sÄ±**         | Linear combina | 3-Comp Hybrid | 3-Comp Hybrid |
| **GÃ¼Ã§ EÅŸik KontrolÃ¼**   | Yok (Not Needed) | Var (0.01W)   | Var (0.01W)   |
| **Policy Gradient**     | Tabular Update | CLIP-PPO      | Q-Learning    |
| **Exploration Strategy**| Îµ-greedy       | Entropy Bonus | Îµ-decay       |

---

## 6. ANALÄ°Z VE GÃ–RSELLEÅTÄ°RME YÃ–NTEMLERÄ°

Sistem performansÄ±nÄ± deÄŸerlendirmek ve senaryo Ã§Ä±ktÄ±larÄ±nÄ± yorumlamak iÃ§in `visualizer.py` modÃ¼lÃ¼ tarafÄ±ndan Ã¼retilen, SCIE makale formatÄ±na uygun iki temel grafik seti kullanÄ±lmaktadÄ±r.

### 6.1. YÃ¶rÃ¼nge ve Olay Analizi (`trajectory.png`)
Bu grafik, simÃ¼lasyonun mekansal (spatial) analizini ve aÄŸ topolojisini gÃ¶sterir.

*   **Ä°Ã§erik:**
    *   **Ä°HA YÃ¶rÃ¼ngesi (Mavi Ã‡izgi):** Ä°HA'nÄ±n gÃ¶rev sÃ¼resince izlediÄŸi fiziksel rotayÄ± gÃ¶sterir.
    *   **IoT DÃ¼ÄŸÃ¼mleri (Renkli Kareler):** Sahadaki sabit sensÃ¶r dÃ¼ÄŸÃ¼mlerinin konumlarÄ±nÄ±; her biri kendine Ã¶zgÃ¼ renkle (Node 0 Mavi, Node 1 Turuncu vb.) gÃ¶sterir.
    *   **BaÅŸarÄ±lÄ± Ä°letiÅŸim (Renkli Noktalar):** Ä°HA'nÄ±n iletiÅŸim kurduÄŸu anlarÄ±, ilgili dÃ¼ÄŸÃ¼mÃ¼n renginde iÅŸaretler. AynÄ± anda Ã§oklu baÄŸlantÄ± varsa noktalar kaydÄ±rÄ±larak (offset) Ã§izilir.
    *   **KarÄ±ÅŸtÄ±rma Kesintileri (KÄ±rmÄ±zÄ± Ã‡arpÄ±):** Ä°letiÅŸimin sadece **Jamming kaynaklÄ±** kesildiÄŸi (ve baÅŸka hiÃ§bir aktif baÄŸlantÄ±nÄ±n olmadÄ±ÄŸÄ±) anlarÄ± gÃ¶sterir.
    *   **Mesafe Kesintileri (Gri Nokta):** Ä°letiÅŸimin sadece mesafe nedeniyle koptuÄŸu anlarÄ± gÃ¶sterir.
    *   **SaldÄ±rgan Konumu (KÄ±rmÄ±zÄ± 'X'):** Jamming kaynaÄŸÄ±nÄ±n konumunu iÅŸaret eder.

*   **Yorumlama:**
    *   Renkli noktalarÄ±n yoÄŸunluÄŸu, Ä°HA'nÄ±n hangi dÃ¼ÄŸÃ¼mle iletiÅŸimde olduÄŸunu netleÅŸtirir.
    *   KÄ±rmÄ±zÄ± Ã§arpÄ±larÄ±n sadece "tam kesinti" anlarÄ±nda Ã§Ä±kmasÄ±, gÃ¶rsel analizi sadeleÅŸtirir.

### 6.2. Metrik Analizi (`metrics_analysis.png`)
Bu grafik, sistemin zamansal (temporal) performansÄ±nÄ± Ã¼Ã§ alt panelde inceler.

1.  **Sinyal Kalitesi ve SaldÄ±rÄ± GÃ¼cÃ¼ (Ãœst Panel):**
    *   *Sol Eksen (Mavi):* AnlÄ±k SINR (dB) deÄŸerini gÃ¶sterir.
    *   *SaÄŸ Eksen (KÄ±rmÄ±zÄ±):* SaldÄ±rganÄ±n jamming gÃ¼cÃ¼nÃ¼ (Watt) gÃ¶sterir.
    *   *Yorum:* KÄ±rmÄ±zÄ± eÄŸrinin yÃ¼kseldiÄŸi (SaldÄ±rÄ± gÃ¼cÃ¼ arttÄ±ÄŸÄ±) anlarda, mavi eÄŸrinin (SINR) dÃ¼ÅŸÃ¼ÅŸÃ¼ gÃ¶zlemlenir. EÅŸik deÄŸerin (Ã–rn: 0 dB) altÄ±na inilen anlar, iletiÅŸimin koptuÄŸu anlardÄ±r.
2.  **Bilgi YaÅŸÄ± - Age of Information (Orta Panel):**
    *   Verinin tazeliÄŸini (Freshness) ifade eder.
    *   *Yorum:* Grafik "testere diÅŸi" (sawtooth) formundadÄ±r. AoI deÄŸerinin lineer olarak arttÄ±ÄŸÄ± (yukarÄ± tÄ±rmandÄ±ÄŸÄ±) sÃ¼reler, verinin alÄ±namadÄ±ÄŸÄ± kesinti sÃ¼releridir. Ani dÃ¼ÅŸÃ¼ÅŸler (sÄ±fÄ±rlanma), baÅŸarÄ±lÄ± paket alÄ±mÄ±nÄ± gÃ¶sterir. Tepe noktalarÄ±nÄ±n yÃ¼ksekliÄŸi, aÄŸdaki gecikme performansÄ±nÄ±n en kÃ¶tÃ¼ durumunu gÃ¶sterir.
3.  **Enerji TÃ¼ketimi (Alt Panel):**
    *   Ä°HA'nÄ±n toplam kÃ¼mÃ¼latif enerji tÃ¼ketimini gÃ¶sterir.
    *   *Yorum:* EÄŸimin (slope) artmasÄ±, Ä°HA'nÄ±n daha fazla gÃ¼Ã§ tÃ¼kettiÄŸi manevralarÄ± veya yÃ¼ksek hÄ±zlarÄ± iÅŸaret eder.

### 6.3. Ä°letiÅŸim Ä°statistikleri (`advanced_metrics.png`)
Bu grafik seti, her bir IoT dÃ¼ÄŸÃ¼mÃ¼nÃ¼n operasyonel performansÄ±nÄ± detaylandÄ±rÄ±r.

1.  **Toplam BaÅŸarÄ±lÄ± Ä°letiÅŸim SÃ¼resi (Ãœst Panel):**
    *   Her bir dÃ¼ÄŸÃ¼mÃ¼n (Node 0, Node 1...) simÃ¼lasyon boyunca toplam kaÃ§ saniye boyunca Ä°HA ile baÅŸarÄ±lÄ± baÄŸlantÄ± kurduÄŸunu gÃ¶steren sÃ¼tun grafiÄŸidir.
    *   *KÄ±rmÄ±zÄ± Kesik Ã‡izgi:* TÃ¼m dÃ¼ÄŸÃ¼mlerin ortalama baÅŸarÄ±lÄ± iletiÅŸim sÃ¼resini gÃ¶sterir.
2.  **Maksimum Kesintisiz Ä°letiÅŸim (Alt Panel):**
    *   Her bir dÃ¼ÄŸÃ¼mÃ¼n baÄŸlantÄ± kopmadan (AoI resetlenmeden) sÃ¼rdÃ¼rebildiÄŸi en uzun iletiÅŸim sÃ¼resini (Streak) gÃ¶sterir.
    *   Bu metrik, sistemin kararlÄ±lÄ±ÄŸÄ±nÄ± ve jamming'in iletiÅŸim sÃ¼rekliliÄŸi Ã¼zerindeki etkisini Ã¶lÃ§mek iÃ§in kritiktir.

### 6.4. Dashboard Analizi
SimÃ¼lasyon tamamlandÄ±ÄŸÄ±nda, yukarÄ±daki tÃ¼m analizler (`Trajectory`, `Metrics`, `Advanced Stats`) tek bir **"Dashboard"** penceresinde operatÃ¶re sunulur. Bu sayede simÃ¼lasyon sonuÃ§larÄ±na bÃ¼tÃ¼ncÃ¼l (holistic) bir bakÄ±ÅŸ aÃ§Ä±sÄ± saÄŸlanÄ±r.

### 6.5. Ä°statistiksel GÃ¼venilirlik Analizi (Robustness)
Bilimsel sonuÃ§larÄ±n gÃ¼venilirliÄŸini saÄŸlamak iÃ§in tekil koÅŸular (Single Run) yerine istatistiksel daÄŸÄ±lÄ±m analizi benimsenmiÅŸtir:
*   **Ã‡oklu Ã‡ekirdek (Multi-Seed):** Her bir algoritma, **100-130 aralÄ±ÄŸÄ±nda seÃ§ilen 30 farklÄ± rastgele tohum** ile test edilerek sonuÃ§larÄ±n varyansÄ± Ã¶lÃ§Ã¼lmÃ¼ÅŸtÃ¼r.
*   **Hata Ã‡ubuklarÄ± (Error Bars):** Performans grafikleri, ortalama deÄŸerin yanÄ± sÄ±ra standart sapmayÄ± (Standard Deviation) da iÃ§erecek ÅŸekilde Ã¼retilmiÅŸtir.
*   **Adil KÄ±yaslama:** TÃ¼m algoritmalar tamamen aynÄ± baÅŸlangÄ±Ã§ koÅŸullarÄ±nda ve aynÄ± rastgele sayÄ± Ã¼reteci (RNG) durumlarÄ±nda yarÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r.


### 6.6. Algoritmik KarÅŸÄ±laÅŸtÄ±rma GrafiÄŸi (`comparison_robustness.png`)
Bu grafik, farklÄ± algoritmalarÄ±n performansÄ±nÄ± dÃ¶rt temel metrik Ã¼zerinden (BaÅŸarÄ±, Takip, GÃ¼Ã§, SINR) yan yana (side-by-side) ve istatistiksel hata paylarÄ±yla karÅŸÄ±laÅŸtÄ±rÄ±r.
*   **Bar Ã‡ubuklarÄ±:** 30 farklÄ± denemenin ortalama deÄŸerini gÃ¶sterir.
*   **Hata Ã‡izgileri (Error Bars):** SonuÃ§larÄ±n standart sapmasÄ±nÄ± (varyansÄ±nÄ±) gÃ¶stererek algoritmanÄ±n kararlÄ±lÄ±ÄŸÄ±nÄ± gÃ¶rselleÅŸtirir.
*   **KullanÄ±m AmacÄ±:** Baseline ve Ã–nerilen YÃ¶ntemler (PPO, LSTM) arasÄ±ndaki farkÄ±n "ÅŸans eseri" olmadÄ±ÄŸÄ±nÄ±, istatistiksel olarak anlamlÄ± (statistically significant) olduÄŸunu kanÄ±tlar.

---

### 6.7. Otomatik EÄŸitim SonuÃ§ GrafiÄŸi (`comparison_result.png`)
Bu grafik, `run_experiments.py` otomasyonu tarafÄ±ndan her eÄŸitim dÃ¶ngÃ¼sÃ¼nÃ¼n sonunda Ã¼retilen "anlÄ±k durum" raporudur.
*   **Ä°Ã§erik:** AlgoritmalarÄ±n son eÄŸitim iterasyonundaki (Ã¶rn. 500. iterasyon) performansÄ±nÄ± (Jammed Node Count, Success Rate, Power) gÃ¶sterir.
*   **FarkÄ±:** `comparison_robustness.png` 30 tekrarlÄ± bir doÄŸrulama iken, bu grafik tek bir eÄŸitimin (Single Run) sonucunu yansÄ±tÄ±r. EÄŸitim sÃ¼recinin hÄ±zlÄ± takibi (Quick Monitoring) iÃ§in kullanÄ±lÄ±r.

---

## 7. ALGORÄ°TMÄ°K PERFORMANS ANALÄ°ZÄ° (QJC vs PPO vs DQN)

Proje kapsamÄ±nda Ã¼Ã§ farklÄ± "SaldÄ±rÄ± ZekasÄ±" modeli birbiriyle yarÄ±ÅŸtÄ±rÄ±lmaktadÄ±r.

### 7.1. Klasik Q-Learning (QJC - Baseline)
*   **Ã‡alÄ±ÅŸma Prensibi:** Durum (state) ve aksiyonlarÄ± (action) iÃ§eren sonlu bir tablo (Look-up Table) tutar.
*   **AvantajÄ±:** Matematiksel olarak basittir ve Ã§ok kÄ±sÄ±tlÄ± iÅŸlem gÃ¼cÃ¼yle Ã§alÄ±ÅŸabilir.
*   **Bu Projedeki RolÃ¼:** Ä°HA'nÄ±n Markov Ã¶rÃ¼ntÃ¼sÃ¼nÃ¼ "istatistiksel" olarak Ã§Ã¶zmekle gÃ¶revlidir. DQN ve PPO iÃ§in bir alt sÄ±nÄ±r (Lower Bound) Ã§izerek, Deep RL'in saÄŸladÄ±ÄŸÄ± katma deÄŸeri Ã¶lÃ§memize yarar.

### 7.2. PPO (Proximal Policy Optimization)
*   **Ã‡alÄ±ÅŸma Prensibi:** "Yeni API Stack" (Ray 2.53+) Ã¼zerinde Ã§alÄ±ÅŸan, sÃ¼rekli aksiyon uzaylarÄ±nÄ± da destekleyen modern bir politika gradiyent algoritmasÄ±dÄ±r.
*   **KarakteristiÄŸi:** EÄŸitim stabilitesi yÃ¼ksektir. GÃ¶zlem uzayÄ±ndaki gÃ¼rÃ¼ltÃ¼lÃ¼ (RSSI, Mesafe) verilere karÅŸÄ± daha dayanÄ±klÄ±dÄ±r.
*   **Beklentimiz:** Ä°HA'nÄ±n hareket Ã¶rÃ¼ntÃ¼sÃ¼nÃ¼ sadece kanal bazlÄ± deÄŸil, mesafeye baÄŸlÄ± gÃ¼Ã§ optimizasyonuyla birlikte Ã¶ÄŸrenmesi.

### 7.3. DQN (Deep Q-Network)
*   **Ã‡alÄ±ÅŸma Prensibi:** Klasik Q-Learning'i derin sinir aÄŸlarÄ±yla birleÅŸtirir. Bu projede "Old API Stack" Ã¼zerinden, MultiDiscrete uzayÄ± Discrete(30) olarak harmonize edilerek koÅŸturulmaktadÄ±r.
*   **KarakteristiÄŸi:** Ã–rnek verimliliÄŸi (Sample Efficiency) yÃ¼ksektir; yani daha az adÄ±mda karmaÅŸÄ±k kararlarÄ± Ã¶ÄŸrenebilir.
*   **Kritik Yama:** DQN'in Ray kÃ¼tÃ¼phanesindeki `ABCMeta` hatasÄ± tarafÄ±mÄ±zca yamalanarak kÃ¼tÃ¼phane stabil hale getirilmiÅŸtir.

### 7.4. PPO-LSTM (Recurrent PPO)
*   **Ã‡alÄ±ÅŸma Prensibi:** PPO mimarisine LSTM (Long Short-Term Memory) katmanÄ± eklenerek ajana "hafÄ±za" yeteneÄŸi kazandÄ±rÄ±lmÄ±ÅŸtÄ±r.
*   **KarakteristiÄŸi:** Zamansal baÄŸÄ±mlÄ±lÄ±klarÄ± (temporal dependencies) Ã¶ÄŸrenebilir. Ä°HA'nÄ±n sadece anlÄ±k deÄŸil, geÃ§miÅŸ hareketlerine de bakarak geleceÄŸi tahmin etmeye Ã§alÄ±ÅŸÄ±r.
*   **Bu Projedeki RolÃ¼:** "HafÄ±zalÄ± Ajan" hipotezini test etmek. (Ancak sonuÃ§lar, bu senaryo iÃ§in Markov Ã¶zniteliÄŸinin yeterli olduÄŸunu, ekstra hafÄ±zanÄ±n karmaÅŸÄ±klÄ±k yarattÄ±ÄŸÄ±nÄ± gÃ¶stermiÅŸtir).

### 7.5. KÄ±yaslama Metrikleri
Deney sonunda Ã¼retilen `comparison_result.png` ÅŸu sorulara yanÄ±t verir:
1.  **Kilitleme HÄ±zÄ± (Tracking Accuracy):** Jammer, UAV'nin kanalÄ±nÄ± ne kadar sÃ¼rede tahmin edebiliyor?
2.  **Zarar Verme Kapasitesi (Success Rate):** UAV'nin veri toplama baÅŸarÄ±sÄ±nÄ± yÃ¼zde kaÃ§ dÃ¼ÅŸÃ¼rebiliyor?
3.  **Enerji VerimliliÄŸi:** En az gÃ¼Ã§ harcayarak en yÃ¼ksek zararÄ± hangi algoritma veriyor?

### 7.6. Deneysel SonuÃ§lar (Robustness Analizi - 30 Seed)

Adil ve kapsamlÄ± bir deÄŸerlendirme iÃ§in her algoritma **100-130 aralÄ±ÄŸÄ±nda seÃ§ilen 30 farklÄ± baÅŸlangÄ±Ã§ tohumu (seed)** ile test edilmiÅŸtir.

#### Performans KarÅŸÄ±laÅŸtÄ±rmasÄ± (Ortalama Â± Standart Sapma)

| Algoritma | BaÅŸarÄ± (JSR) | Kanal EÅŸleÅŸme (Tracking) | Ort. GÃ¼Ã§ (W) | SINR (dB) |
|-----------|--------------|--------------------------|--------------|-----------|
| **PPO (Ã–nerilen)** | **%57.4 Â± 10.9** ğŸ† | **%60.1** | 0.429 | **3.94** |
| **PPO-LSTM** | %53.6 Â± 8.6 | %56.0 | **0.305** ğŸƒ | 3.91 |
| **DQN** | %29.4 Â± 11.8 | %33.3 | **0.241** | 5.10 |
| **Baseline (QJC)** | %1.9 Â± 0.8 | %1.1 | 0.400 | 3.78 |

#### Temel Bulgular
- âœ… **PPO Åampiyon:** Baseline'a gÃ¶re **~30 kat** (%1.9 -> %57.4) performans artÄ±ÅŸÄ± saÄŸlamÄ±ÅŸtÄ±r. SÃ¼rekli aksiyon uzayÄ± ve kararlÄ± Ã¶ÄŸrenme yapÄ±sÄ± (Clipped Objective) bu baÅŸarÄ±nÄ±n anahtarÄ±dÄ±r.
- âœ… **LSTM VerimliliÄŸi:** PPO-LSTM, Baseline'a gÃ¶re **%24 daha az enerji** harcayarak (%0.30W vs 0.40W) Ã§ok yÃ¼ksek baÅŸarÄ± (%53.6) elde etmiÅŸtir. Gereksiz saldÄ±rÄ±larÄ± filtreleyerek "Sessiz ve Derinden" bir strateji izlemiÅŸtir.
- âœ… **Baseline BaÅŸarÄ±sÄ±zlÄ±ÄŸÄ±:** "YapÄ±sal KÃ¶rlÃ¼k" nedeniyle (mesafe/spektrum algÄ±sÄ± yok), $d^2$ yol kaybÄ± fiziÄŸi karÅŸÄ±sÄ±nda Ã§aresiz kalmÄ±ÅŸtÄ±r.
- âœ… **SINR Paradoksu:** PPO ve Baseline benzer ortalama SINR Ã¼retmiÅŸtir. PPO "etkili" darbelerle iletiÅŸimi tamamen keserken (Deep Fade), Baseline sadece "etkisiz" arka plan gÃ¼rÃ¼ltÃ¼sÃ¼ yaratmÄ±ÅŸtÄ±r. PPO'nun ortalamasÄ±nÄ±n yÃ¼ksek kalmasÄ±, Ä°HA'nÄ±n bu darbelerden kaÃ§Ä±p temiz kanallara sÄ±ÄŸÄ±nmasÄ±ndandÄ±r.
- âœ… **DQN'in SessizliÄŸi:** Dinamik 3D uzayda (Konum+Frekans+GÃ¼Ã§) kaybolmuÅŸ ve ceza almamak iÃ§in pasif kalmayÄ± (Sparsity Trap) seÃ§miÅŸtir.

**Not:** TÃ¼m istatistikler `paper/robustness_results_30seeds.json` dosyasÄ±nda saklanmaktadÄ±r.

---

## 8. GELÄ°ÅÄ°M GÃœNLÃœÄÃœ (CHANGE LOG)

### [02.02.2026 01:07] - BaÅŸlangÄ±Ã§ SÃ¼rÃ¼mÃ¼ (v1.0.0)
**YapÄ±lan DeÄŸiÅŸiklikler:**
1.  **AltyapÄ± Kurulumu:** TÃ¼m temel modÃ¼ller (`main`, `config`, `physics`, `entities`, `env`) sÄ±fÄ±rdan kodlandÄ±.
2.  **Model Entegrasyonu:** Tez Ã¶nerisindeki matematiksel formÃ¼ller `physics.py` iÃ§erisine fonksiyonel olarak gÃ¶mÃ¼ldÃ¼.
3.  **Senaryo TasarÄ±mÄ±:** Ä°HA'nÄ±n dairesel devriye gezdiÄŸi ve saldÄ±rganÄ±n rastgele jamming uyguladÄ±ÄŸÄ± temel "Baseline" senaryo kurgulandÄ±.
4.  **Hata DÃ¼zeltmeleri:**
    *   `pandas` ve `numpy` kÃ¼tÃ¼phanelerindeki sÃ¼rÃ¼m uyumsuzluÄŸu giderildi.
    *   `entities.py` iÃ§indeki Ã§oklu kalÄ±tÄ±m (Diamond Problem) yapÄ±sÄ±nda `super()` kullanÄ±mÄ± yerine aÃ§Ä±k sÄ±nÄ±f Ã§aÄŸrÄ±larÄ± (Explicit init calls) yapÄ±larak `__init__` hatasÄ± dÃ¼zeltildi.
5.  **Loglama Sistemi:** SimÃ¼lasyon verilerinin anlÄ±k kaydÄ± iÃ§in `SimulationLogger` sÄ±nÄ±fÄ± geliÅŸtirildi.
6.  **GÃ¶rselleÅŸtirme ModÃ¼lÃ¼:** SonuÃ§larÄ±n analiz iÃ§in CSV verilerini okuyup grafik Ã¼reten `visualizer.py` modÃ¼lÃ¼ sisteme eklendi.

**AmaÃ§:**
Tez Ã§alÄ±ÅŸmasÄ±nÄ±n simÃ¼lasyon gereksinimlerini karÅŸÄ±layan, doÄŸrulanmÄ±ÅŸ (verified) ve veri Ã¼retebilen kararlÄ± bir sÃ¼rÃ¼mÃ¼n oluÅŸturulmasÄ±.

### [02.02.2026 01:40] - Otomasyon SÃ¼rÃ¼mÃ¼ (v1.1.0)
**YapÄ±lan DeÄŸiÅŸiklikler:**
1.  **Tam Otomasyon:** `main.py` gÃ¼ncellenerek simÃ¼lasyon bitiminde `visualizer` modÃ¼lÃ¼nÃ¼n otomatik tetiklenmesi saÄŸlandÄ±.
2.  **GÃ¶rselleÅŸtirme Ä°yileÅŸtirmesi:** Ä°HA rotasÄ± Ã¼zerinde baÅŸarÄ±lÄ±/baÅŸarÄ±sÄ±z iletiÅŸim ve IoT dÃ¼ÄŸÃ¼m konumlarÄ± eklendi.
3.  **Veri ZenginleÅŸtirme:** `environment.py` loglarÄ±na dÃ¼ÄŸÃ¼m konumlarÄ± ve baÄŸlantÄ± durumu eklendi.

### [02.02.2026 01:42] - Parametre Revizyonu (v1.1.1)
**YapÄ±lan DeÄŸiÅŸiklikler:**
1.  **SaldÄ±rgan GÃ¼cÃ¼ Revizyonu:** `MAX_JAMMING_POWER` 2.0W -> 1.0W dÃ¼ÅŸÃ¼rÃ¼ldÃ¼.
2.  **KonfigÃ¼rasyon AyrÄ±mÄ±:** Ortam parametreleri `core/env_config.py` dosyasÄ±na taÅŸÄ±narak fiziksel parametrelerden (`core/config.py`) izole edildi.

### [02.02.2026 02:40] - Navigasyon ve GÃ¶rselleÅŸtirme Paketi (v1.2.0)
**YapÄ±lan DeÄŸiÅŸiklikler:**
1.  **Waypoint Navigasyonu:** Ä°HA'nÄ±n dairesel uÃ§uÅŸu yerine, dÃ¼ÄŸÃ¼mleri sÄ±rasÄ±yla (0->N) ziyaret ettiÄŸi "Target Tracking" modeline geÃ§ildi.
2.  **GerÃ§ekÃ§i Jamming AlanÄ±:** AnlÄ±k gÃ¶rselleÅŸtirmede (`visualization.py`), basit daire yerine SINR < 0dB olan bÃ¶lgeleri tarayan **Dinamik Kontur GrafiÄŸi** eklendi.
3.  **GeliÅŸmiÅŸ Trajectory Analizi:**
    *   **DÃ¼ÄŸÃ¼m Renkleri:** Her dÃ¼ÄŸÃ¼m benzersiz bir renge (tab10) atandÄ±.
    *   **Offset Logic:** Ã‡oklu baÄŸlantÄ± durumunda noktalarÄ±n Ã¼st Ã¼ste binmesi, koordinat kaydÄ±rma (offset) yÃ¶ntemiyle engellendi.
    *   **AkÄ±llÄ± Filtreleme:** EÄŸer Ä°HA en az bir dÃ¼ÄŸÃ¼me baÄŸlÄ±ysa, gÃ¶rsel kirliliÄŸi Ã¶nlemek iÃ§in diÄŸer dÃ¼ÄŸÃ¼mlerin Jammed/Out-of-Range sembolleri gizlendi.

### [02.02.2026 03:00] - Mimari RefaktÃ¶r (v1.2.1)
**YapÄ±lan DeÄŸiÅŸiklikler:**
1.  **Dizin YapÄ±sÄ± DÃ¼zenlemesi:** KonfigÃ¼rasyon dosyalarÄ± (`config.py`, `env_config.py`) `core/` klasÃ¶rÃ¼nden yeni oluÅŸturulan `confs/` klasÃ¶rÃ¼ne taÅŸÄ±ndÄ±.
2.  **ModÃ¼larite:** KonfigÃ¼rasyon ve Ã‡ekirdek mantÄ±ÄŸÄ± birbirinden tamamen izole edildi. TÃ¼m modÃ¼ller (`simulation`, `visualization`, `core`) yeni yapÄ±ya uygun olarak gÃ¼ncellendi.

### [06.02.2026 15:55] - Multi-Agent Mimari GÃ¶Ã§Ã¼ (v1.3.0)
**YapÄ±lan DeÄŸiÅŸiklikler:**
1.  **PettingZoo GeÃ§iÅŸi:** OpenAI Gymnasium (`gym.Env`) yapÄ±sÄ±ndan PettingZoo (`ParallelEnv`) yapÄ±sÄ±na geÃ§ildi. Bu sayede simÃ¼lasyon, tek ajanlÄ± yapÄ±dan Ã§ok ajanlÄ± (Multi-Agent) yapÄ±ya evrildi.
2.  **Ã–lÃ§eklenebilir Ajan TanÄ±mÄ±:** Ä°HA (`uav_0`), Jammer (`jammer_0`) ve IoT DÃ¼ÄŸÃ¼mleri (`node_0`,`node_1`,...) artÄ±k sistemde birer "ajan" olarak tanÄ±mlanmÄ±ÅŸtÄ±r.
3.  **Kural TabanlÄ± KontrolcÃ¼:** Ä°HA'nÄ±n navigasyon mantÄ±ÄŸÄ±, Ã§evre kodundan (`env.step`) Ã§Ä±karÄ±larak harici bir kontrolcÃ¼ sÄ±nÄ±fÄ±na (`UAVRuleBasedController`) taÅŸÄ±ndÄ±. Bu, Ä°HA'nÄ±n ileride farklÄ± politika algoritmalarÄ±yla (RL vb.) deÄŸiÅŸtirilebilmesine olanak tanÄ±maktadÄ±r.
4.  **AÄŸ ve Oyun Teorisi AltyapÄ±sÄ±:** Yeni mimari, oyun teorik yaklaÅŸÄ±mlarÄ±n (Ã¶rn. Jammer ve Ä°HA arasÄ±ndaki Stackelberg oyunlarÄ±) uygulanabilmesi iÃ§in gerekli olan eÅŸ zamanlÄ± aksiyon (simultaneous action) altyapÄ±sÄ±nÄ± saÄŸlamaktadÄ±r.

### [06.02.2026 16:15] - GeliÅŸmiÅŸ Metrikler ve Dashboard (v1.4.0)
**YapÄ±lan DeÄŸiÅŸiklikler:**
1.  **Yeni HaberleÅŸme Metrikleri:** Her dÃ¼ÄŸÃ¼m iÃ§in "Toplam BaÅŸarÄ±lÄ± Ä°letiÅŸim SÃ¼resi" ve "Maksimum Kesintisiz Ä°letiÅŸim SÃ¼resi" (Max Continuous Streak) metrikleri sisteme eklendi.
2.  **Dashboard ArayÃ¼zÃ¼:** SimÃ¼lasyon sonunda Ã¼retilen tÃ¼m grafikleri (YÃ¶rÃ¼nge, Zaman Serileri, Ä°statistikler) tek bir pencerede birleÅŸtiren `show_dashboard()` Ã¶zelliÄŸi `visualizer.py` modÃ¼lÃ¼ne entegre edildi.
3.  **VarlÄ±k GÃ¼ncellemesi:** `IoTNode` sÄ±nÄ±fÄ±, kendi iletiÅŸim tarihÃ§esini (History) tutacak ÅŸekilde akÄ±llandÄ±rÄ±ldÄ±.

### [06.02.2026 17:00] - DavranÄ±ÅŸsal GerÃ§ekÃ§ilik (v1.5.0)
**YapÄ±lan DeÄŸiÅŸiklikler:**
1.  **Hover (AskÄ±da Kalma) MantÄ±ÄŸÄ±:** Ä°HA'nÄ±n sadece Ã¼zerinden geÃ§mek yerine, dÃ¼ÄŸÃ¼mlere vardÄ±ÄŸÄ±nda verimli veri toplamak adÄ±na 5 saniye boyunca havada asÄ±lÄ± kalmasÄ± (Hover) saÄŸlandÄ±.
2.  **Dinamik Navigasyon:** Hedefe varÄ±ÅŸ kriteri, simÃ¼lasyon adÄ±m bÃ¼yÃ¼klÃ¼ÄŸÃ¼ne (Step Size) gÃ¶re dinamik hale getirilerek "overshoot" (hedefi Ä±skalama) problemleri Ã§Ã¶zÃ¼ldÃ¼.
3.  **GÃ¼Ã§ TÃ¼ketimi GÃ¶rÃ¼nÃ¼rlÃ¼ÄŸÃ¼:** Analiz modÃ¼lÃ¼nde enerji grafiklerinin anlÄ±k gÃ¼Ã§ deÄŸiÅŸimlerini (Hover vs Flight) yansÄ±tmasÄ± saÄŸlandÄ± (KullanÄ±cÄ± isteÄŸi Ã¼zerine kÃ¼mÃ¼latif gÃ¶sterime geri dÃ¶nÃ¼ldÃ¼ ancak altyapÄ± bu detayÄ± desteklemektedir).

### [06.02.2026 21:00] - AkÄ±llÄ± Tehdit & RL Entegrasyonu (v1.6.0)
**YapÄ±lan DeÄŸiÅŸiklikler:**
1.  **Ã‡oklu Frekans KanalÄ±:** Sistem artÄ±k 2.4, 5.0 ve 5.8 GHz kanallarÄ±nÄ± desteklemekte ve fiziksel katman (Path Loss, PA Efficiency) buna gÃ¶re modellenmektedir.
2.  **AkÄ±llÄ± Tehdit Modeli (QJC):** Liao ve ark. (2025) tarafÄ±ndan Ã¶nerilen Q-Learning tabanlÄ± Jammer Kanal SeÃ§im algoritmasÄ± (SmartAttacker sÄ±nÄ±fÄ±na) entegre edildi.
3.  **Reaktif Markov Ä°HA:** Ä°HA'nÄ±n jamming saldÄ±rÄ±sÄ±na uÄŸradÄ±ÄŸÄ±nda rastgele deÄŸil, belirli bir olasÄ±lÄ±ksal matrise (Markov Zinciri) gÃ¶re kanal deÄŸiÅŸtirdiÄŸi "Hareketli Hedef" modeli oluÅŸturuldu.
4.  **RLLib Entegrasyonu:** `scripts/train.py` dosyasÄ± ile Ray RLLib (PPO) Ã¼zerinde Jammer'Ä±n bu Markov modelini Ã¶ÄŸrenmesi iÃ§in eÄŸitim altyapÄ±sÄ± kuruldu.

### [07.02.2026 00:10] - Adillik ve KÄ±yaslama Paketi (v1.7.0)
**YapÄ±lan DeÄŸiÅŸiklikler:**
1.  **Sensing Mode (GerÃ§ekÃ§i AlgÄ±lama):**
    *   RL AjanÄ±nÄ±n (Jammer) gÃ¶zlem uzayÄ±ndan hileli "God View" (Tam Koordinat) verisi Ã§Ä±karÄ±ldÄ±.
    *   Yerine, sadece **Mesafe** (Distance) ve **Sinyal GÃ¼cÃ¼** (RSSI) gibi gerÃ§ek hayatta sensÃ¶rlerle Ã¶lÃ§Ã¼lebilen veriler eklendi.
2.  **Adil KÄ±yaslama (Algorithmic Fairness):**
    *   Baseline (QJC) algoritmasÄ±nÄ±n, PPO eÄŸitim sÃ¼relerine denk (60K adÄ±m) deneyim kazanmasÄ± iÃ§in **Ã–n EÄŸitim (Pre-training)** modÃ¼lÃ¼ (`scripts/train_baseline.py`) eklendi.
    *   BÃ¶ylece "EÄŸitimsiz Baseline vs EÄŸitilmiÅŸ RL" adaletsizliÄŸi giderildi.
3.  **Algoritmik Ã‡eÅŸitlilik:**
    *   **PPO:** SÃ¼rekli (Continuous) politika optimizasyonu (New API Stack).
    *   **DQN:** AyrÄ±k (Discrete) aksiyon uzayÄ± optimizasyonu (Old API Stack).
    *   **Baseline:** Tablosal (Tabular) Q-Learning.
    *   ÃœÃ§ algoritmayÄ± tek komutla yarÄ±ÅŸtÄ±ran `scripts/run_experiments.py` otomasyonu geliÅŸtirildi.
4.  **Otomatik Raporlama:** TÃ¼m sonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±rmalÄ± sÃ¼tun grafiklerine (`comparison_result.png`) dÃ¶ken analiz modÃ¼lÃ¼ eklendi.

### [07.02.2026 02:00] - RLLib Yama ve Otomasyon Paketi (v1.8.0)
**YapÄ±lan DeÄŸiÅŸiklikler:**
1.  **Ray RLLib Hata DÃ¼zeltmesi (Bug Fix):**
    *   Ray 2.53.0 sÃ¼rÃ¼mÃ¼ndeki DQN algoritmasÄ±nÄ±n "Old API Stack" yolunda kilitlenmesine neden olan `TypeError: argument of type 'ABCMeta' is not iterable` hatasÄ± tespit edildi.
    *   `rllib/algorithms/algorithm.py` dosyasÄ±na `isinstance(..., str)` kontrolÃ¼ eklenerek yerel kÃ¼tÃ¼phane yamalandÄ±.
    *   DÃ¼zeltme, Ray projesine resmi Pull Request olarak gÃ¶nderildi (DCO imzalÄ±).
2.  **Tam Otomatik Deney HattÄ± (Experiment Pipeline):**
    *   `scripts/run_experiments.py` scripti geliÅŸtirilerek; Baseline (QJC), PPO ve DQN modellerinin sÄ±rayla eÄŸitilmesi, deÄŸerlendirilmesi ve karÅŸÄ±laÅŸtÄ±rmalÄ± rapor Ã¼retilmesi otomatikleÅŸtirildi.
3.  **Temizlik ve Optimizasyon:**
    *   Gereksiz geÃ§ici dosyalar ve bÃ¼yÃ¼k boyutlu fork dosyalarÄ± silinerek proje alanÄ± optimize edildi.
4.  **DokÃ¼mantasyon GÃ¼ncellemesi:**
    *   `README.md` ve `.gitignore` dosyalarÄ± yeni deney Ã§Ä±ktÄ±larÄ±nÄ± ve yama sÃ¼recini kapsayacak ÅŸekilde gÃ¼ncellendi.

**AmaÃ§:**
SimÃ¼lasyon ortamÄ±nÄ±n akademik bir test yataÄŸÄ± (testbed) olarak kararlÄ±lÄ±ÄŸÄ±nÄ± saÄŸlamak ve Ray kÃ¼tÃ¼phanesi kaynaklÄ± engelleri kalÄ±cÄ± olarak aÅŸmak.

Bu sÃ¼rÃ¼m ile proje, "SaldÄ±rgan KÄ±yaslama" (Attacker Comparison) makalesi iÃ§in gerekli test yataÄŸÄ±na dÃ¶nÃ¼ÅŸmÃ¼ÅŸtÃ¼r.

### [07.02.2026 03:45] - KonfigÃ¼rasyon Refactoring ve GPU DesteÄŸi (v1.9.0)
**YapÄ±lan DeÄŸiÅŸiklikler:**
1.  **Merkezi KonfigÃ¼rasyon YapÄ±sÄ± (`confs/model_config.py`):**
    *   **GlobalConfig:** TÃ¼m algoritmalar iÃ§in ortak parametreler (`RANDOM_SEED`, `FLATTEN_ACTIONS`) merkezi hale getirildi.
    *   **RLConfig â†’ PPOConfig:** PPO parametreleri yeniden adlandÄ±rÄ±larak netleÅŸtirildi ve model mimarisi (`FCNET_HIDDENS`) eklendi.
    *   **DQNConfig (YENÄ°):** DQN iÃ§in Ã¶zel hyperparameter sÄ±nÄ±fÄ± oluÅŸturuldu (LR, GAMMA, TRAIN_BATCH_SIZE, TARGET_NETWORK_UPDATE_FREQ, REPLAY_BUFFER_CAPACITY, vb.).
    *   **QJCConfig GeniÅŸletildi:** `TRAIN_EPISODES`, `SAVE_PATH`, `MAX_POWER_LEVEL` parametreleri merkezi yapÄ±ya taÅŸÄ±ndÄ±.
    
2.  **Reproducibility (Yeniden Ãœretilebilirlik) Garantisi:**
    *   Random seed deÄŸeri (`RANDOM_SEED = 42`) tÃ¼m training scriptlerinde hardcoded olarak tekrar ediliyordu. ArtÄ±k tek bir noktadan (`GlobalConfig.RANDOM_SEED`) yÃ¶netiliyor.
    *   Seed deÄŸiÅŸtirmek iÃ§in tek satÄ±r edit yeterli.

3.  **PyTorch CUDA Kurulumu ve GPU DesteÄŸi:**
    *   **Sorun Tespiti:** PyTorch CPU-only versiyonu (2.5.1+cpu) yÃ¼klÃ¼ydÃ¼, CUDA 12.2 kurulu olmasÄ±na raÄŸmen GPU tanÄ±nmÄ±yordu.
    *   **Ã‡Ã¶zÃ¼m:** Conda install timeout sorunu nedeniyle pip kullanÄ±larak `torch-2.5.1+cu121` kuruldu.
    *   **DonanÄ±m DoÄŸrulamasÄ±:** NVIDIA GeForce RTX 3080 baÅŸarÄ±yla tanÄ±ndÄ± ve aktif edildi.
    *   **Performans Etkisi:** GPU desteÄŸi ile eÄŸitim hÄ±zÄ± ~5-10x artÄ±ÅŸ gÃ¶sterdi.

4.  **Action Space Harmonizasyonu (Adalet Ä°yileÅŸtirmesi):**
    *   **Sorun:** PPO `MultiDiscrete([3, 10])` kullanÄ±rken DQN `Discrete(30)` kullanÄ±yordu. Bu PPO'ya %60-70 yapÄ±sal avantaj saÄŸlÄ±yordu (2.5x gradient efficiency, structured exploration).
    *   **Ã‡Ã¶zÃ¼m:** Her iki algoritma da `Discrete(30)` kullanacak ÅŸekilde harmonize edildi (`GlobalConfig.FLATTEN_ACTIONS = True`).
    *   **SonuÃ§:** %100 adil kÄ±yaslama garantisi saÄŸlandÄ±.

5.  **Gamma Harmonizasyonu:**
    *   PPO'nun `GAMMA = 0.95` deÄŸeri, Baseline ve DQN'in `0.9` deÄŸeriyle eÅŸitlenerek (PPOConfig.GAMMA = 0.9) tÃ¼m algoritmalarÄ±n aynÄ± Ã¶dÃ¼l iskontolama stratejisini kullanmasÄ± saÄŸlandÄ±.

6.  **API Stack ÅeffaflÄ±ÄŸÄ±:**
    *   PPO: New API Stack (varsayÄ±lan, modern, aktif geliÅŸtirme)
    *   DQN: Old API Stack (gereklilik, MultiDiscrete native desteÄŸi yok)
    *   Her algoritma kendi en stabil stack'ini kullanÄ±yor, performans adaleti korunuyor.

**AmaÃ§:**
Proje bakÄ±mÄ±nÄ± kolaylaÅŸtÄ±rmak, hyperparameter tuning'i merkezileÅŸtirmek ve tÃ¼m deney koÅŸullarÄ±nÄ± %100 yeniden Ã¼retilebilir kÄ±lmak. AyrÄ±ca GPU desteÄŸi ile eÄŸitim sÃ¼resini optimize edip bilimsel iterasyon hÄ±zÄ±nÄ± artÄ±rmak.

Bu sÃ¼rÃ¼m ile proje, "Fair Algorithmic Comparison" standartlarÄ±na tam uyumlu hale getirilmiÅŸtir.

### [07.02.2026 04:16] - KonfigÃ¼rasyon Ä°yileÅŸtirmeleri v1.9.1 (Patch)
**YapÄ±lan DeÄŸiÅŸiklikler:**
1.  **TRAIN_ITERATIONS MerkezileÅŸtirilmesi:**
    *   `TRAIN_ITERATIONS` parametresi tÃ¼m config class'larÄ±ndan kaldÄ±rÄ±lÄ±p `GlobalConfig`'e taÅŸÄ±ndÄ±.
    *   ArtÄ±k eÄŸitim iterasyonunu deÄŸiÅŸtirmek iÃ§in tek satÄ±r edit yeterli.
    *   **Etkilenen:** `QJCConfig`, `PPOConfig`, `DQNConfig` â†’ `GlobalConfig.TRAIN_ITERATIONS`

2.  **PPO API Stack Harmonizasyonu:**
    *   PPO, DQN ile aynÄ± performans ve ÅŸeffaflÄ±k iÃ§in Old API Stack'e geÃ§irildi.
    *   **Fayda:** Her iki algoritma da aynÄ± API stack kullanÄ±yor â†’ GPU raporlamasÄ± ve davranÄ±ÅŸ tam eÅŸit.
    
3.  **DQN Training Intensity Optimizasyonu:**
    *   DQN'de `training_intensity=1` parametresi eklendi.
    *   **Sorun:** DQN her iterasyonda 1M gradient update yapÄ±yordu (60 dakika).
    *   **Ã‡Ã¶zÃ¼m:** Training intensity ile sÄ±nÄ±rlandÄ±rÄ±ldÄ± â†’ **2 dakikaya dÃ¼ÅŸtÃ¼** (~30x hÄ±zlanma).
    
4.  **Ray Metrics UyarÄ±larÄ±nÄ±n Gizlenmesi:**
    *   `RAY_DISABLE_METRICS_EXPORT=1` environment variable eklendi.
    *   ZararsÄ±z "metrics exporter" uyarÄ±larÄ± temiz Ã§Ä±ktÄ± iÃ§in susturuldu.

**AmaÃ§:**
Kod kalitesini artÄ±rmak, eÄŸitim sÃ¼resini optimize etmek ve geliÅŸtirici deneyimini iyileÅŸtirmek.

### [08.02.2026 23:30] - Paralel EÄŸitim ve UI Paketi (v2.0.0)
**YapÄ±lan DeÄŸiÅŸiklikler:**
1.  **Paralel EÄŸitim (Parallel Execution):**
    *   `subprocess` ve `threading` kÃ¼tÃ¼phaneleri kullanÄ±larak Baseline (QJC), PPO ve DQN algoritmalarÄ± artÄ±k **eÅŸ zamanlÄ±** olarak eÄŸitilmektedir.
    *   Bu sayede toplam deney sÃ¼resi yaklaÅŸÄ±k **3 kat** kÄ±salmÄ±ÅŸtÄ±r (Ã–rn: 1 saat -> 20 dakika).
    *   Otomasyon scripti (`run_experiments.py`) tÃ¼m kaynak yÃ¶netimini (GPU/CPU) otomatik yapar.

2.  **GeliÅŸmiÅŸ KullanÄ±cÄ± Deneyimi (UI/UX):**
    *   **AnlÄ±k Progress Bar:** Terminal Ã¼zerinden her algoritmanÄ±n ilerleme durumu (AdÄ±m/Toplam) ve yÃ¼zdesi canlÄ± olarak takip edilebilmektedir. 
    *   **Renkli Ã‡Ä±ktÄ±lar:** Durumlar (OK=YeÅŸil, Running=SarÄ±, Fail=KÄ±rmÄ±zÄ±) ANSI renk kodlarÄ±yla gÃ¶rselleÅŸtirilmiÅŸtir.
    *   **Ray RLLib Entegrasyonu:** `ProgressCallback` sÄ±nÄ±fÄ± sayesinde Ray'in karmaÅŸÄ±k loglarÄ± filtrelenerek temiz bir ilerleme Ã§ubuÄŸuna dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸtÃ¼r.

3.  **Esnek KonfigÃ¼rasyon ve ArgÃ¼manlar:**
    *   `--debug`: DetaylÄ± hata ayÄ±klama modu. TÃ¼m subprocess Ã§Ä±ktÄ±larÄ±nÄ± (stdout/stderr) ekrana basar.
    *   `--ui <saniye>`: Terminal gÃ¼ncelleme sÄ±klÄ±ÄŸÄ±nÄ± ayarlar (VarsayÄ±lan: 3s).

4.  **Artifact YÃ¶netimi:**
    *   Her deney Ã§alÄ±ÅŸtÄ±rmasÄ± iÃ§in `artifacts/YYYY-MM-DD_HH-MM-SS/` formatÄ±nda izole bir klasÃ¶r oluÅŸturulur.
    *   Bu klasÃ¶r iÃ§inde eÄŸitim modelleri, loglar ve karÅŸÄ±laÅŸtÄ±rma grafikleri dÃ¼zenli bir hiyerarÅŸide saklanÄ±r. Eski `logs/` yapÄ±sÄ±ndan daha temiz bir yapÄ±ya geÃ§ilmiÅŸtir.

**AmaÃ§:**
### [09.02.2026 23:00] - LSTM ve GÃ¶rselleÅŸtirme Paketi (v2.1.0)
**YapÄ±lan DeÄŸiÅŸiklikler:**
1.  **PPO-LSTM Entegrasyonu:**
    *   Ray RLLib'in Recurrent Network (LSTM) desteÄŸi projeye eklendi (`train_ppo_lstm.py`).
    *   `PPOLSTMConfig` yapÄ±landÄ±rma sÄ±nÄ±fÄ± oluÅŸturuldu.
    *   DeÄŸerlendirme (`evaluate.py`) scripti, gizli durumlarÄ± (hidden states - h, c) yÃ¶netecek ÅŸekilde gÃ¼ncellendi.
    
2.  **KarÅŸÄ±laÅŸtÄ±rma GÃ¶rselleÅŸtirmesi (Refined Visualization):**
    *   **Adil BaÅŸlangÄ±Ã§:** TÃ¼m Deep RL algoritmalarÄ±nÄ±n grafikleri, veri toplama fazÄ±nÄ± yansÄ±tacak ÅŸekilde 1000. adÄ±mdan baÅŸlatÄ±ldÄ±.
    *   **Baseline HizalamasÄ±:** Baseline verisi, Deep RL batch size'Ä±na (1000) uygun ÅŸekilde yeniden Ã¶rneklenerek (resampling) grafiklerin x-ekseninde tam hizalanmasÄ± saÄŸlandÄ±.
    *   **(0,0) NoktasÄ±:** YanÄ±ltÄ±cÄ± olmamasÄ± iÃ§in yapay (0,0) noktasÄ± kaldÄ±rÄ±ldÄ±, doÄŸal Ã¶ÄŸrenme sÃ¼reÃ§leri yansÄ±tÄ±ldÄ±.
    
3.  **DQN Hata YÃ¶netimi:**
    *   Paralel Ã§alÄ±ÅŸmada DQN'in bazen zaman aÅŸÄ±mÄ±na uÄŸramasÄ± (timeout) sorunu analiz edildi ve result.json varlÄ±ÄŸÄ± kontrol edilerek "False Negative" durumlarÄ± engellendi.

**AmaÃ§:**
HafÄ±zalÄ± (Recurrent) modellerin etkisini Ã¶lÃ§mek ve grafik okumayÄ± bilimsel standartlara (elmalarla elmalar) taÅŸÄ±mak.

### [10.02.2026 00:00] - Robustness ve Ä°statistik Paketi (v2.2.0)
**YapÄ±lan DeÄŸiÅŸiklikler:**
1.  **30-Seed Robust Evaluation:**
    *   Bilimsel geÃ§erliliÄŸi artÄ±rmak iÃ§in tÃ¼m algoritmalar **30 farklÄ± random seed** (Range: 100-129) ile test edildi.
    *   `scripts/evaluate_paper_robustness.py` scripti geliÅŸtirildi.
    *   SonuÃ§lar ortalama ve standart sapma (Mean Â± Std) olarak raporlandÄ±.

2.  **Teorik Analiz DerinleÅŸtirme:**
    *   Baseline baÅŸarÄ±sÄ±zlÄ±ÄŸÄ±nÄ±n sebebi "YapÄ±sal KÃ¶rlÃ¼k" (Structural Blindness) ve $d^2$ fiziksel kÄ±sÄ±tÄ± olarak tanÄ±mlandÄ±.
    *   SINR Paradoksu (PPO ve Baseline'Ä±n benzer ortalama vermesi), "Etkili GÃ¼Ã§" (Effective Power) ve "Ä°HA Adaptasyonu" (UAV Adaptation) kavramlarÄ± ile aÃ§Ä±klandÄ±.

3.  **Deneysel Bulgular:**
    *   PPO'nun baÅŸarÄ±sÄ± istatistiksel olarak kanÄ±tlandÄ± (%57.4 Â± 10.9).
    *   PPO-LSTM'in enerji verimliliÄŸi (%24 tasarruf) ve kararlÄ±lÄ±ÄŸÄ± (dÃ¼ÅŸÃ¼k varyans) ortaya kondu.

**AmaÃ§:**
Makale (Paper) iÃ§in gerekli olan gÃ¼venilir, tekrarlanabilir ve istatistiksel olarak anlamlÄ± veri setini oluÅŸturmak.
